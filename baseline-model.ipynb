{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc95da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For importing modules\n",
    "import sys\n",
    "\n",
    "\n",
    "# final pre-processing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, Input, BatchNormalization\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8134298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/path/to/2014_07_13_test')\n",
    "import generate_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9640c8",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c00e596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter small cases\n",
    "filter_case = ['case_00018', 'case_00031', 'case_00042', 'case_00056', 'case_00088', 'case_00090', 'case_00092', \n",
    "               'case_00106', 'case_00120', 'case_00133', 'case_00183', 'case_00200', 'case_00211', 'case_00228',\n",
    "               'case_00234', 'case_00237', 'case_00249', 'case_00277', 'case_00288', 'case_00291']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d267974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load validation set\n",
    "val_case = ['case_00233', 'case_00089', 'case_00050', 'case_00112', 'case_00258', 'case_00246', 'case_00157',\n",
    "            'case_00149','case_00184']\n",
    "test_case = ['case_00221', 'case_00259', 'case_00087', 'case_00254', 'case_00098', 'case_00023', 'case_00041',\n",
    "             'case_00080', 'case_00101', 'case_00164', 'case_00002', 'case_00110', 'case_00030', 'case_00068',\n",
    "             'case_00026', 'case_00063', 'case_00006', 'case_00048', 'case_00250', 'case_00238', 'case_00015',\n",
    "             'case_00111', 'case_00278', 'case_00133', 'case_00284', 'case_00282', 'case_00269', 'case_00039',\n",
    "             'case_00033', 'case_00108', 'case_00175', 'case_00161', 'case_00256', 'case_00119', 'case_00286',\n",
    "             'case_00077', 'case_00162', 'case_00270', 'case_00271', 'case_00285', 'case_00174', 'case_00147',\n",
    "             'case_00215', 'case_00150', 'case_00052', 'case_00231', 'case_00198', 'case_00117', 'case_00138',\n",
    "             'case_00211', 'case_00190', 'case_00248', 'case_00235', 'case_00049', 'case_00074', 'case_00107',\n",
    "             'case_00218', 'case_00001', 'case_00193', 'case_00067', 'case_00289', 'case_00072', 'case_00044',\n",
    "             'case_00294', 'case_00298', 'case_00263', 'case_00038', 'case_00299', 'case_00249', 'case_00225',\n",
    "             'case_00217', 'case_00178', 'case_00082', 'case_00035', 'case_00034', 'case_00047', 'case_00276',\n",
    "             'case_00151', 'case_00226', 'case_00086', 'case_00176']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c1f8db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases = [ 'case_' + str(number).zfill(5) for number in range(300)] # create list of all cases\n",
    "train_case = [x for x in all_cases if x not in val_case and x not in test_case] # take only cases not in test and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c68af3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_part_label_dict(labels_dict, list_of_cases):\n",
    "    return {k: labels_dict[k] for k in list_of_cases}\n",
    "\n",
    "def load_data(rootdir, img_dir, json_path, list_cases):\n",
    "    val_path = generate_input.processed_image_paths(rootdir, img_dir)\n",
    "    labels_dict = generate_input.malignant_labels_to_dict(json_path)\n",
    "    labels_dict_short = generate_part_label_dict(labels_dict, list_cases)\n",
    "    image_dict_short = generate_input.load_nifti_img_and_mask_as_numpy(val_path, list_cases)\n",
    "    x_set, y_set = generate_input.fill_set(list_cases, labels_dict_short, image_dict_short, labels_dict)\n",
    "    x_set = generate_input.adding_channel(x_set)\n",
    "    return x_set, y_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e95fd48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = load_data('./preprocessed-data/', 'images', '../kits21/kits21/data/kits.json', val_case)\n",
    "x_test, y_test = load_data('./preprocessed-data/', 'images', '../kits21/kits21/data/kits.json', test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdae94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_data('./preprocessed-data/', 'images', '../kits21/kits21/data/kits.json', train_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd758f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, y_train, x_val, y_val, x_test, y_test, id_val, id_test = generate_input.generate_data_input(\n",
    "#     '../kits21/kits21/data/kits.json', n_samples = 300, neg_pct = 100, rootdir = './preprocessed-data/', \n",
    "#     img_dir = 'images', mask_dir = 'masks', val_split = 9, test_split = 81)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b438df",
   "metadata": {},
   "source": [
    "## Upsampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06ee0eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_reshape = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2] * x_train.shape[3])\n",
    "sm = SMOTE(random_state=64)\n",
    "x_smote, y_smote = sm.fit_resample(x_train_reshape, y_train)\n",
    "x_smote = x_smote.reshape(x_smote.shape[0], x_train.shape[1], x_train.shape[2], x_train.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97103fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_smote, y_smote = shuffle(x_smote, y_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1443c8af",
   "metadata": {},
   "source": [
    "## Developing baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac892aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a code is taken from https://stackoverflow.com/questions/62916904/failed-copying-input-tensor-from-cpu-to-gpu-in-order-to-run-gatherve-dst-tensor\n",
    "\n",
    "batch_size = 32\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\" Send data to the model using TF in specified sizes of batch \"\"\"\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "train_gen = DataGenerator(x_smote, y_smote, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88392ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# draft model\n",
    "#inputs = Input(shape=(224, 224, 3))\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=2)\n",
    "\n",
    "resnet = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(128,128,3))\n",
    "\n",
    "for layer in resnet.layers[:170]:\n",
    "    layer.trainable = False\n",
    "\n",
    "metrics_list = [tf.keras.metrics.AUC(name = 'auc'),\n",
    "                tf.keras.metrics.BinaryAccuracy(name = 'accuracy')]\n",
    "\n",
    "#calculate class weights\n",
    "class_weights = {0 : 25, 1 : 1} \n",
    "\n",
    "optimizer_fn = tf.keras.optimizers.experimental.RMSprop(learning_rate=0.001, jit_compile = False)\n",
    "#optimizer_fn = tf.keras.optimizers.Adam(learning_rate=0.00002)\n",
    "\n",
    "x = Flatten()(resnet.output)\n",
    "x = Dense(1024, activation = 'relu', kernel_regularizer='l2')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation = 'relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation = 'relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128, activation = 'relu', kernel_regularizer='l2')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "x = Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(resnet.input, x)\n",
    "\n",
    "model.compile(optimizer = optimizer_fn, loss='binary_crossentropy', metrics= metrics_list)\n",
    "model.summary()\n",
    "model.fit(train_gen, validation_data = (x_val, y_val), epochs=5, batch_size = batch_size, class_weight = class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b3797283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 3s 46ms/step - loss: 1.4998 - auc: 0.5277 - accuracy: 0.9321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4998470544815063, 0.5276820063591003, 0.9321120977401733]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(x_val, y_val)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6d4d60ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 19:52:13.470334: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 5s 47ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0d701795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9417528579205225\n",
      "0.989136649514008\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_val, y_pred.round()) \n",
    "recall = recall_score(y_val, y_pred.round())\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1c424d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  107],\n",
       "       [  19, 1730]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "34189632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       107\n",
      "         1.0       0.94      0.99      0.96      1749\n",
      "\n",
      "    accuracy                           0.93      1856\n",
      "   macro avg       0.47      0.49      0.48      1856\n",
      "weighted avg       0.89      0.93      0.91      1856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bcc392",
   "metadata": {},
   "source": [
    "## Evaluation of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8480de31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 22s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c0df661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  271,   528],\n",
       "       [ 4680, 11681]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_test.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a99b5258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.05      0.34      0.09       799\n",
      "         1.0       0.96      0.71      0.82     16361\n",
      "\n",
      "    accuracy                           0.70     17160\n",
      "   macro avg       0.51      0.53      0.46     17160\n",
      "weighted avg       0.91      0.70      0.78     17160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215e4104",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "497aa301",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model1_binary2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model1_binary2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5948ccab",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32be7e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('baseline_model/model1_binary2.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"baseline_model/model1_binary2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75e67d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 11:45:52.826066: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 4s 46ms/step - loss: 1.0652 - auc: 0.6680 - accuracy: 0.6972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0651888847351074, 0.6679624319076538, 0.6971982717514038]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate loaded model on test data\n",
    "optimizer_fn = tf.keras.optimizers.experimental.RMSprop(learning_rate=0.001, jit_compile = False)\n",
    "metrics_list = [tf.keras.metrics.AUC(name = 'auc'),\n",
    "                tf.keras.metrics.BinaryAccuracy(name = 'accuracy')]\n",
    "loaded_model.compile(optimizer = optimizer_fn, loss='binary_crossentropy', metrics= metrics_list)\n",
    "score1 = loaded_model.evaluate(x_val, y_val)\n",
    "score1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4010f5",
   "metadata": {},
   "source": [
    "## Majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b082e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load validation set\n",
    "val_case = ['case_00233', 'case_00089', 'case_00050', 'case_00112', 'case_00258', 'case_00246', 'case_00157', 'case_00149','case_00184']\n",
    "test_case = ['case_00221', 'case_00259', 'case_00087', 'case_00254', 'case_00098', 'case_00023', 'case_00041',\n",
    "             'case_00080', 'case_00101', 'case_00164', 'case_00002', 'case_00110', 'case_00030', 'case_00068',\n",
    "             'case_00026', 'case_00063', 'case_00006', 'case_00048', 'case_00250', 'case_00238', 'case_00015',\n",
    "             'case_00111', 'case_00278', 'case_00133', 'case_00284', 'case_00282', 'case_00269', 'case_00039',\n",
    "             'case_00033', 'case_00108', 'case_00175', 'case_00161', 'case_00256', 'case_00119', 'case_00286',\n",
    "             'case_00077', 'case_00162', 'case_00270', 'case_00271', 'case_00285', 'case_00174', 'case_00147',\n",
    "             'case_00215', 'case_00150', 'case_00052', 'case_00231', 'case_00198', 'case_00117', 'case_00138',\n",
    "             'case_00211', 'case_00190', 'case_00248', 'case_00235', 'case_00049', 'case_00074', 'case_00107',\n",
    "             'case_00218', 'case_00001', 'case_00193', 'case_00067', 'case_00289', 'case_00072', 'case_00044',\n",
    "             'case_00294', 'case_00298', 'case_00263', 'case_00038', 'case_00299', 'case_00249', 'case_00225',\n",
    "             'case_00217', 'case_00178', 'case_00082', 'case_00035', 'case_00034', 'case_00047', 'case_00276',\n",
    "             'case_00151', 'case_00226', 'case_00086', 'case_00176']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddcd5fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_channel_dict(image_dict):\n",
    "    \"\"\"Convert from one channel to three channel images that are stored in dictionary \"\"\"\n",
    "    for key in image_dict:\n",
    "        image_dict[key] = generate_input.adding_channel(image_dict[key])\n",
    "    return image_dict\n",
    "\n",
    "def load_data_to_evaluate_by_majority_voting(rootdir, img_dir, json_path, list_cases):\n",
    "    \"\"\" Load images and labels in dictionary format \"\"\"\n",
    "    val_path = generate_input.processed_image_paths(rootdir, img_dir)\n",
    "    labels_dict = generate_input.malignant_labels_to_dict(json_path)\n",
    "    labels_dict_short = generate_part_label_dict(labels_dict, list_cases)\n",
    "    labels_dict_short = {key: float(value) for key, value in labels_dict_short.items()}\n",
    "    \n",
    "    image_dict_short = generate_input.load_nifti_img_and_mask_as_numpy(val_path, list_cases)\n",
    "    image_dict_short = adding_channel_dict(image_dict_short)\n",
    "    return image_dict_short, labels_dict_short\n",
    "    \n",
    "def create_prediction_dict(image_dict, model):\n",
    "    \"\"\" Create dictionary with prediction on patient-level using majority voting \"\"\"\n",
    "    pred_dict = {}\n",
    "    for key in image_dict:\n",
    "        y_pred = model.predict(image_dict[key])\n",
    "        pred_dict[key] = np.round(np.sum(y_pred)/len(y_pred))\n",
    "    return pred_dict\n",
    "\n",
    "def create_true_and_prediction_lists(true_dict, pred_dict):\n",
    "    \"\"\" Convert dictionaries into lists for evaluation \"\"\"\n",
    "    common_keys = true_dict.keys() & pred_dict.keys()\n",
    "    true_lst = []\n",
    "    pred_lst = [] \n",
    "    for key in common_keys:\n",
    "        true_lst.append(true_dict[key])\n",
    "        pred_lst.append(pred_dict[key])   \n",
    "    return true_lst, pred_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aa8300",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fadc46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dict, labels_val = load_data_to_evaluate_by_majority_voting('./preprocessed-data/', 'images', '../kits21/kits21/data/kits.json', val_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c04d5e4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 67ms/step\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "4/4 [==============================] - 0s 75ms/step\n",
      "4/4 [==============================] - 1s 203ms/step\n",
      "19/19 [==============================] - 1s 48ms/step\n",
      "3/3 [==============================] - 0s 38ms/step\n",
      "18/18 [==============================] - 1s 39ms/step\n",
      "3/3 [==============================] - 0s 38ms/step\n",
      "5/5 [==============================] - 0s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "val_pred_dict = create_prediction_dict(val_dict, loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef0eb1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_true_lst, val_pred_lst = create_true_and_prediction_lists(labels_val, val_pred_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2fba1cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 6]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(val_true_lst, val_pred_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a62364e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.86      0.75      0.80         8\n",
      "\n",
      "    accuracy                           0.67         9\n",
      "   macro avg       0.43      0.38      0.40         9\n",
      "weighted avg       0.76      0.67      0.71         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_true_lst, val_pred_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33df51b5",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0bfb927",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict, test_label_dict = load_data_to_evaluate_by_majority_voting('./preprocessed-data/', 'images', '../kits21/kits21/data/kits.json', test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b814e24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 420ms/step\n",
      "4/4 [==============================] - 1s 241ms/step\n",
      "9/9 [==============================] - 1s 113ms/step\n",
      "3/3 [==============================] - 0s 46ms/step\n",
      "4/4 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 1s 949ms/step\n",
      "19/19 [==============================] - 1s 71ms/step\n",
      "3/3 [==============================] - 0s 39ms/step\n",
      "5/5 [==============================] - 0s 80ms/step\n",
      "3/3 [==============================] - 0s 86ms/step\n",
      "3/3 [==============================] - 1s 323ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "3/3 [==============================] - 0s 79ms/step\n",
      "9/9 [==============================] - 1s 114ms/step\n",
      "3/3 [==============================] - 1s 485ms/step\n",
      "3/3 [==============================] - 0s 85ms/step\n",
      "5/5 [==============================] - 1s 270ms/step\n",
      "16/16 [==============================] - 1s 44ms/step\n",
      "21/21 [==============================] - 1s 42ms/step\n",
      "21/21 [==============================] - 1s 40ms/step\n",
      "3/3 [==============================] - 0s 122ms/step\n",
      "23/23 [==============================] - 1s 50ms/step\n",
      "3/3 [==============================] - 1s 409ms/step\n",
      "3/3 [==============================] - 1s 488ms/step\n",
      "3/3 [==============================] - 1s 479ms/step\n",
      "9/9 [==============================] - 1s 60ms/step\n",
      "3/3 [==============================] - 0s 140ms/step\n",
      "17/17 [==============================] - 2s 98ms/step\n",
      "3/3 [==============================] - 0s 43ms/step\n",
      "3/3 [==============================] - 1s 358ms/step\n",
      "9/9 [==============================] - 0s 52ms/step\n",
      "8/8 [==============================] - 1s 172ms/step\n",
      "15/15 [==============================] - 1s 39ms/step\n",
      "3/3 [==============================] - 0s 186ms/step\n",
      "3/3 [==============================] - 0s 40ms/step\n",
      "6/6 [==============================] - 1s 136ms/step\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "3/3 [==============================] - 1s 356ms/step\n",
      "20/20 [==============================] - 1s 44ms/step\n",
      "20/20 [==============================] - 2s 89ms/step\n",
      "6/6 [==============================] - 1s 123ms/step\n",
      "2/2 [==============================] - 1s 804ms/step\n",
      "20/20 [==============================] - 1s 40ms/step\n",
      "3/3 [==============================] - 1s 240ms/step\n",
      "20/20 [==============================] - 1s 52ms/step\n",
      "5/5 [==============================] - 1s 155ms/step\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "3/3 [==============================] - 1s 249ms/step\n",
      "4/4 [==============================] - 1s 204ms/step\n",
      "3/3 [==============================] - 1s 248ms/step\n",
      "8/8 [==============================] - 0s 66ms/step\n",
      "22/22 [==============================] - 1s 45ms/step\n",
      "7/7 [==============================] - 0s 41ms/step\n",
      "6/6 [==============================] - 0s 59ms/step\n",
      "4/4 [==============================] - 0s 103ms/step\n",
      "5/5 [==============================] - 1s 275ms/step\n",
      "6/6 [==============================] - 0s 62ms/step\n",
      "3/3 [==============================] - 1s 287ms/step\n",
      "7/7 [==============================] - 1s 206ms/step\n",
      "8/8 [==============================] - 1s 114ms/step\n",
      "2/2 [==============================] - 0s 244ms/step\n",
      "2/2 [==============================] - 1s 476ms/step\n",
      "4/4 [==============================] - 0s 77ms/step\n",
      "4/4 [==============================] - 0s 102ms/step\n",
      "5/5 [==============================] - 1s 162ms/step\n",
      "5/5 [==============================] - 1s 150ms/step\n",
      "4/4 [==============================] - 0s 109ms/step\n",
      "4/4 [==============================] - 1s 191ms/step\n",
      "34/34 [==============================] - 2s 69ms/step\n",
      "5/5 [==============================] - 0s 42ms/step\n",
      "2/2 [==============================] - 1s 587ms/step\n",
      "8/8 [==============================] - 1s 113ms/step\n",
      "3/3 [==============================] - 1s 42ms/step\n",
      "4/4 [==============================] - 1s 198ms/step\n",
      "10/10 [==============================] - 0s 49ms/step\n",
      "6/6 [==============================] - 1s 123ms/step\n",
      "4/4 [==============================] - 0s 104ms/step\n",
      "6/6 [==============================] - 1s 120ms/step\n",
      "14/14 [==============================] - 1s 51ms/step\n",
      "6/6 [==============================] - 1s 126ms/step\n",
      "3/3 [==============================] - 0s 90ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred_dict = create_prediction_dict(test_dict, loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de529025",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true_lst, test_pred_lst = create_true_and_prediction_lists(test_label_dict, test_pred_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27fb67be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  5]\n",
      " [11 63]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_true_lst, test_pred_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3087d6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.15      0.29      0.20         7\n",
      "         1.0       0.93      0.85      0.89        74\n",
      "\n",
      "    accuracy                           0.80        81\n",
      "   macro avg       0.54      0.57      0.54        81\n",
      "weighted avg       0.86      0.80      0.83        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_true_lst, test_pred_lst))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
